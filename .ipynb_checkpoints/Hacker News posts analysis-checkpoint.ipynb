{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Looking for Ways to Get the Most Comments on Hacker News Posts\n",
    "Hacker News is a site started by the startup [incubator Y](https://www.ycombinator.com) Combinator, where user-submitted stories (known as \"posts\") receive votes and comments, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of the Hacker News listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "* We're specifically interested in posts with titles that begin with either Ask HN or Show HN. Users submit Ask HN posts to ask the Hacker News community a specific question. Below are a few examples\n",
    "\n",
    "* Likewise, users submit Show HN posts to show the Hacker News community a project, product, or just something interesting. Below are a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01'],\n",
       " ['10301696',\n",
       "  'Note by Note: The Making of Steinway L1037 (2007)',\n",
       "  'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
       "  '8',\n",
       "  '2',\n",
       "  'walterbell',\n",
       "  '9/30/2015 4:12']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing necessary liabraries\n",
    "# import pandas as pd\n",
    "\n",
    "# hn = pd.read_csv(\"hacker_news.csv\")\n",
    "# hn.head()\n",
    "\n",
    "from csv import reader\n",
    "import datetime as dt\n",
    "\n",
    "opened_file = open(\"hacker_news.csv\")\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "hn[:5]\n",
    "\n",
    "#Extracting the first row of data to a variable\n",
    "headers = hn[0]\n",
    "del hn[0]\n",
    "hn[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20100\n",
      "20100\n"
     ]
    }
   ],
   "source": [
    "ask_posts = [] \n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "# Verifying length \n",
    "print(len(other_posts) + len(show_posts) + len(ask_posts))\n",
    "print(len(hn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Average Number of Comments for Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.038417431192661"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding total number of comments in ask_post list\n",
    "total_ask_comments = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    num_comments = post[4]\n",
    "    num_comments = int(num_comments)\n",
    "    total_ask_comments += num_comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "\n",
    "avg_ask_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.31669535283993"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding total number of comments in show_post list\n",
    "total_show_comments = 0\n",
    "for post in show_posts:\n",
    "    num_comments = post[4]\n",
    "    num_comments = int(num_comments)\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "avg_show_comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is then seen from  the above analysis that the average number of posts for ask post is greater than show post. This shows that according to this analysis, people mostly post on Hacker News to ask questions.\n",
    "\n",
    "According to this analysis, further analysis will be focused on ask posts since they are likely to receive more comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Number of Ask Posts and Comments by Hour Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n",
      "--------\n",
      "{'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n"
     ]
    }
   ],
   "source": [
    "result_list = [] ## List of lists containinng dates and comments\n",
    "#Dictionary holding the number of number of `ASK HN` in every\n",
    "#our of the day.\n",
    "counts_by_hour = {}  \n",
    "\n",
    "#Dictionary containing the number of comments during eah \n",
    "#hour of the day\n",
    "comments_by_hour = {}\n",
    "\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for post in ask_posts:\n",
    "    created_at = post[6]\n",
    "    num_comments = post[4]\n",
    "    num_comments = int(num_comments)\n",
    "    result_list.append([created_at,num_comments])\n",
    "    \n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    num_comments = row[1]\n",
    "    date = dt.datetime.strptime(date,date_format)\n",
    "    hour = date.strftime(\"%H\")\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = num_comments\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += num_comments\n",
    "        \n",
    "print(counts_by_hour)\n",
    "\n",
    "print(\"--------\")\n",
    "\n",
    "print(comments_by_hour)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time for us to calculate the **average number  of comments for ASk HN Posts by hour**. This will be done by considering the two dictionaries created above, that is, the `counts_by_hour` and `comments_by_hour` dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for key in comments_by_hour:\n",
    "    avg_by_hour.append([key,comments_by_hour[key] / counts_by_hour[key]])\n",
    "    \n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_tup = {}\n",
    "# for hour, avg in avg_by_hour:\n",
    "#     sort_tup[avg] = hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result sofar obtained, can not really be a right for drawing conclusions because that will be visually difficult since the list of lists is not sorted.\n",
    "\n",
    "Our next target is to get the `avg_by_hour` list of list sorted and the top five hours with the highest number of comments in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first five top hours for highest rating\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for item in avg_by_hour:\n",
    "    hour,avg = item\n",
    "    swap_avg_by_hour.append([avg,hour])\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "print(f\"first five top hours for highest rating\")\n",
    "sorted_swap[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let us now try to format the result to be visuaaally more pleasing so that conclusion can easily be drawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n",
      "13:00: 14.74 average comments per post\n",
      "10:00: 13.44 average comments per post\n",
      "14:00: 13.23 average comments per post\n",
      "18:00: 13.20 average comments per post\n",
      "17:00: 11.46 average comments per post\n",
      "01:00: 11.38 average comments per post\n",
      "11:00: 11.05 average comments per post\n",
      "19:00: 10.80 average comments per post\n",
      "08:00: 10.25 average comments per post\n",
      "05:00: 10.09 average comments per post\n",
      "12:00: 9.41 average comments per post\n",
      "06:00: 9.02 average comments per post\n",
      "00:00: 8.13 average comments per post\n",
      "23:00: 7.99 average comments per post\n",
      "07:00: 7.85 average comments per post\n",
      "03:00: 7.80 average comments per post\n",
      "04:00: 7.17 average comments per post\n",
      "22:00: 6.75 average comments per post\n",
      "09:00: 5.58 average comments per post\n"
     ]
    }
   ],
   "source": [
    "for item in sorted_swap:\n",
    "    average,hour = item\n",
    "    date = dt.datetime.strptime(hour,\"%H\")\n",
    "    date = date.strftime(\"%H:%M\")\n",
    "    print(\"{}: {:.2f} average comments per post\".format(date,average))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "From our analysis, top hour with the highest number of comments is **15:00(3:00pm)**, followed by **02:00(02:00am)**, then by **20:00(8pm)**.\n",
    "\n",
    "This results show that the hour ***15:00*** has the highest chance of receiving comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
